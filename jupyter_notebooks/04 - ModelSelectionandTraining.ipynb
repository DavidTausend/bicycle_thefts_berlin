{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Training Notebook\n",
    "\n",
    "## Objectives:\n",
    "- Train multiple machine learning models on the dataset.\n",
    "- Perform hyperparameter tuning to find the best model.\n",
    "- Save trained models for further evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/bicycle_thefts_berlin/jupyter_notebooks\n",
      "['0' '1' 'Unbekannt' 0 1]\n",
      "['Sonstiger schwerer Diebstahl von FahrrÃ¤dern'\n",
      " 'Einfacher Diebstahl von FahrrÃ¤dern'\n",
      " 'Sonstiger schwerer Diebstahl in/aus Keller/Boden von FahrrÃ¤dern'\n",
      " 'Einfacher Diebstahl aus Keller/Boden von FahrrÃ¤dern']\n",
      "[False  True]\n",
      "Data has been loaded and split into features and target.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1917/2683941404.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  TrainSet_encoded = pd.read_csv('/workspace/bicycle_thefts_berlin/outputs/datasets/featured/TrainSet_Featured.csv')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "# Load preprocessed data\n",
    "TrainSet_encoded = pd.read_csv('/workspace/bicycle_thefts_berlin/outputs/datasets/featured/TrainSet_Featured.csv')\n",
    "TestSet_encoded = pd.read_csv('/workspace/bicycle_thefts_berlin/outputs/datasets/featured/TestSet_Featured.csv')\n",
    "\n",
    "# Inspect the unique values in potential target columns\n",
    "print(TrainSet_encoded['VERSUCH'].unique())\n",
    "print(TrainSet_encoded['ERFASSUNGSGRUND'].unique())\n",
    "print(TrainSet_encoded['DELIKT_Keller- und Bodeneinbruch'].unique())\n",
    "\n",
    "# Assuming 'VERSUCH' is the target column\n",
    "target_column = 'VERSUCH'\n",
    "\n",
    "# Separating features and target variable\n",
    "X_train = TrainSet_encoded.drop(target_column, axis=1)  \n",
    "y_train = TrainSet_encoded[target_column]\n",
    "X_test = TestSet_encoded.drop(target_column, axis=1)\n",
    "y_test = TestSet_encoded[target_column]\n",
    "\n",
    "print(\"Data has been loaded and split into features and target.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model Selection\n",
    "We’ll define a list of models that we want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training Models\n",
    "For each model, train it on the training data and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGELEGT_AM                             object\n",
      "TATZEIT_ANFANG_STUNDE                  float64\n",
      "TATZEIT_ENDE_DATUM                      object\n",
      "TATZEIT_ENDE_STUNDE                      int64\n",
      "ERFASSUNGSGRUND                         object\n",
      "ART_DES_FAHRRADS_Fahrrad                  bool\n",
      "ART_DES_FAHRRADS_Herrenfahrrad            bool\n",
      "ART_DES_FAHRRADS_Kinderfahrrad            bool\n",
      "ART_DES_FAHRRADS_Lastenfahrrad            bool\n",
      "ART_DES_FAHRRADS_Mountainbike             bool\n",
      "ART_DES_FAHRRADS_Rennrad                  bool\n",
      "ART_DES_FAHRRADS_diverse FahrrÃ¤der       bool\n",
      "DELIKT_Keller- und Bodeneinbruch          bool\n",
      "TATZEIT_ANFANG_YEAR                      int64\n",
      "TATZEIT_ANFANG_MONTH                     int64\n",
      "dtype: object\n",
      "object\n",
      "Non-numeric columns in X_train: Index(['ANGELEGT_AM', 'TATZEIT_ENDE_DATUM', 'ERFASSUNGSGRUND',\n",
      "       'ART_DES_FAHRRADS_Fahrrad', 'ART_DES_FAHRRADS_Herrenfahrrad',\n",
      "       'ART_DES_FAHRRADS_Kinderfahrrad', 'ART_DES_FAHRRADS_Lastenfahrrad',\n",
      "       'ART_DES_FAHRRADS_Mountainbike', 'ART_DES_FAHRRADS_Rennrad',\n",
      "       'ART_DES_FAHRRADS_diverse FahrrÃ¤der',\n",
      "       'DELIKT_Keller- und Bodeneinbruch'],\n",
      "      dtype='object')\n",
      "Any NaN in y_train: 8\n",
      "Length of X_train: 34500\n",
      "Length of y_train: 34500\n",
      "Length of X_test: 8627\n",
      "Length of y_test: 8627\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ANGELEGT_AM_2022-01-02\n- ANGELEGT_AM_2022-01-03\n- TATZEIT_ENDE_DATUM_2022-01-02\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 90\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[1;32m     89\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m---> 90\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Calculate accuracy and F1-score\u001b[39;00m\n\u001b[1;32m     93\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_train, y_pred_train)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/sklearn/linear_model/_base.py:382\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 382\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    384\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/sklearn/linear_model/_base.py:363\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    361\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 363\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ANGELEGT_AM_2022-01-02\n- ANGELEGT_AM_2022-01-03\n- TATZEIT_ENDE_DATUM_2022-01-02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check the data types in X_train and y_train\n",
    "print(X_train.dtypes)\n",
    "print(y_train.dtypes)\n",
    "\n",
    "# Check if there are any non-numeric columns in X_train and y_train\n",
    "non_numeric_columns = X_train.select_dtypes(exclude=['number']).columns\n",
    "print(\"Non-numeric columns in X_train:\", non_numeric_columns)\n",
    "\n",
    "if len(non_numeric_columns) > 0:\n",
    "    # Apply get_dummies to the non-numeric columns\n",
    "    X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "    # Align the columns between train and test after encoding\n",
    "    X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Ensure y_train is numeric\n",
    "if y_train.dtypes != 'int64' and y_train.dtypes != 'float64':\n",
    "    y_train = pd.to_numeric(y_train, errors='coerce')\n",
    "\n",
    "# Check for NaN or invalid values after conversion\n",
    "print(\"Any NaN in y_train:\", y_train.isnull().sum())\n",
    "\n",
    "# Drop NaN rows if any\n",
    "if y_train.isnull().sum() > 0:\n",
    "    y_train = y_train.dropna()\n",
    "\n",
    "# Remove rows with NaN in y_train and the corresponding rows in X_train\n",
    "valid_indices = y_train.dropna().index  # Get indices where y_train is not NaN\n",
    "\n",
    "# Filter both X_train and y_train using these indices\n",
    "X_train = X_train.loc[valid_indices]\n",
    "y_train = y_train.loc[valid_indices]\n",
    "\n",
    "# Now check if the lengths are the same\n",
    "print(\"Length of X_train:\", len(X_train))\n",
    "print(\"Length of y_train:\", len(y_train))\n",
    "\n",
    "# Ensure y_test is numeric\n",
    "if y_test.dtypes != 'int64' and y_test.dtypes != 'float64':\n",
    "    y_test = pd.to_numeric(y_test, errors='coerce')\n",
    "\n",
    "# Check for NaN in y_test\n",
    "if y_test.isnull().sum() > 0:\n",
    "    y_test = y_test.dropna()\n",
    "\n",
    "# Remove rows with NaN in X_test that correspond to NaN in y_test\n",
    "valid_indices_test = y_test.dropna().index  # Get indices where y_test is not NaN\n",
    "X_test = X_test.loc[valid_indices_test]\n",
    "y_test = y_test.loc[valid_indices_test]\n",
    "\n",
    "# Now check if the lengths are the same\n",
    "print(\"Length of X_test:\", len(X_test))\n",
    "print(\"Length of y_test:\", len(y_test))\n",
    "\n",
    "# Check and convert date columns\n",
    "if 'TATZEIT_ANFANG_DATUM' in TrainSet_encoded.columns:\n",
    "    TrainSet_encoded['TATZEIT_ANFANG_DATUM'] = pd.to_datetime(TrainSet_encoded['TATZEIT_ANFANG_DATUM'])\n",
    "    TrainSet_encoded['TATZEIT_ANFANG_YEAR'] = TrainSet_encoded['TATZEIT_ANFANG_DATUM'].dt.year\n",
    "    TrainSet_encoded['TATZEIT_ANFANG_MONTH'] = TrainSet_encoded['TATZEIT_ANFANG_DATUM'].dt.month\n",
    "    TrainSet_encoded = TrainSet_encoded.drop(columns=['TATZEIT_ANFANG_DATUM', 'TATZEIT_ENDE_DATUM'])\n",
    "\n",
    "if 'TATZEIT_ANFANG_DATUM' in TestSet_encoded.columns:\n",
    "    TestSet_encoded['TATZEIT_ANFANG_DATUM'] = pd.to_datetime(TestSet_encoded['TATZEIT_ANFANG_DATUM'])\n",
    "    TestSet_encoded['TATZEIT_ANFANG_YEAR'] = TestSet_encoded['TATZEIT_ANFANG_DATUM'].dt.year\n",
    "    TestSet_encoded['TATZEIT_ANFANG_MONTH'] = TestSet_encoded['TATZEIT_ANFANG_DATUM'].dt.month\n",
    "    TestSet_encoded = TestSet_encoded.drop(columns=['TATZEIT_ANFANG_DATUM', 'TATZEIT_ENDE_DATUM'])\n",
    "\n",
    "# Ensure there are no object (string) columns left in the data\n",
    "# Drop any non-numeric columns or convert them to numeric\n",
    "X_train = X_train.select_dtypes(include=['number'])\n",
    "X_test = X_test.select_dtypes(include=['number'])\n",
    "\n",
    "# Dictionary to store model performance\n",
    "model_performance = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and F1-score\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    train_f1 = f1_score(y_train, y_pred_train)\n",
    "    test_f1 = f1_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Store the performance\n",
    "    model_performance[model_name] = {\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_f1': train_f1,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name} -> Test Accuracy: {test_accuracy:.4f}, Test F1: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Hyperparameter Tuning (Optional)\n",
    "Use GridSearchCV for hyperparameter tuning on the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best F1 score:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_random_forest_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best F1 score: \", grid_search.best_score_)\n",
    "\n",
    "# Save the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "joblib.dump(best_rf_model, 'best_random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save the Best Model\n",
    "Save the trained models for further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression saved as Logistic Regression_model.pkl\n",
      "Random Forest saved as Random Forest_model.pkl\n",
      "SVM saved as SVM_model.pkl\n",
      "K-Nearest Neighbors saved as K-Nearest Neighbors_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save each model\n",
    "for model_name, model in models.items():\n",
    "    joblib.dump(model, f'{model_name}_model.pkl')\n",
    "    print(f\"{model_name} saved as {model_name}_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Summary of Results\n",
    "Summarize the performance of the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     train_accuracy  test_accuracy  train_f1  test_f1\n",
      "Logistic Regression        0.996000       0.997566  0.000000      0.0\n",
      "Random Forest              0.996116       0.997102  0.056338      0.0\n",
      "SVM                        0.996000       0.997566  0.000000      0.0\n",
      "K-Nearest Neighbors        0.996000       0.997566  0.000000      0.0\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(model_performance).T\n",
    "print(results_df)\n",
    "\n",
    "# Save results to a CSV\n",
    "results_df.to_csv('model_performance_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Next Steps\n",
    "The next steps to improve and finalize the model development process are as follows:\n",
    "\n",
    "1. Cross-Validation for Model Evaluation:\n",
    "\n",
    "Perform cross-validation to assess how well the model generalizes to new data. This involves dividing the dataset into multiple folds and training the model on different subsets, which provides a more robust evaluation of its performance. Use techniques like cross_val_score or GridSearchCV in sklearn to implement this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores:  [0.99608696 0.99608696 0.99594203 0.99594203 0.99594203]\n",
      "Mean CV Accuracy:  0.9960000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy Scores: \", scores)\n",
    "print(\"Mean CV Accuracy: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'max_depth': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ANGELEGT_AM_2022-01-02\n- ANGELEGT_AM_2022-01-03\n- TATZEIT_ENDE_DATUM_2022-01-02\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/sklearn/linear_model/_base.py:382\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 382\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    384\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/sklearn/linear_model/_base.py:363\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    361\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 363\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ANGELEGT_AM_2022-01-02\n- ANGELEGT_AM_2022-01-03\n- TATZEIT_ENDE_DATUM_2022-01-02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
